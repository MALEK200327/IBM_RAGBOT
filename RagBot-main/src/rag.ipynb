{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For IBM watsonx on IBM Cloud\n",
    "\n",
    "import getpass\n",
    "\n",
    "# cloud_apikey = getpass.getpass(\"Type your IBM Cloud API key: \")\n",
    "cloud_apikey = \"1C_e21y5BVpQrTQjXgZCyXGkwt27NgsAlhWS2BmRrC-5\"\n",
    "\n",
    "url = \"https://us-south.ml.cloud.ibm.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = { \n",
    "    \"url\"    : url, \n",
    "    \"apikey\" : cloud_apikey\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"Knowlege_Base_for_LLM.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zblithereplz ● Developing Secure Software - Learn the security basics to develop software that is hardened against attacks, and understand how you can reduce the damage and speed the response when a vulnerability is exploited. Thanks to the involvement of OpenSSF , a cross-industry collaboration that brings together leaders to improve the security of open source software by\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 45.9M/45.9M [00:05<00:00, 9.14MiB/s]\n",
      "Verifying: 100%|██████████| 45.9M/45.9M [00:00<00:00, 297MiB/s]\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\nzblithereplz\\n\"],\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=250,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "all_splits = text_splitter.split_documents(pages)\n",
    "print(all_splits[1].page_content.replace(\"\\n\", \" \"))\n",
    "embedding = GPT4AllEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embedding,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a747/ai_grp/RagBot/env/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "search_term = \"advanced quantum computing\"\n",
    "documents = retriever.get_relevant_documents(search_term)\n",
    "for doc in retriever.get_relevant_documents(search_term):\n",
    "    doc.page_content = doc.page_content.replace(\"\\n\", \" \").replace(\"zblithereplz\", \"\").replace(\"-\", \"\").replace(\"—\", \"\")\n",
    "    # print(doc.page_content[:1000] + \"...\")\n",
    "    # print(len(doc.page_content))\n",
    "article_txt = max(documents, key=lambda doc: len(doc.page_content)).page_content.replace(\"\\n\", \" \").replace(\"zblithereplz\", \"\").replace(\"-\", \"\").replace(\"—\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Article:\n",
    "###\n",
    "%s\n",
    "###\n",
    "\n",
    "You are a chatbot that recommends courses to students. You are provided with an article that contains information about various courses.\n",
    "Based on the users input you will recommend a course to the user.\n",
    "Answer in a complete sentence, with proper capitalization and punctuation. \n",
    "If there is no good answer in the article, say \"Sorry, I don't know\".\n",
    "Always include the course name in your answer.\n",
    "Always include the course link in your answer.\n",
    "\n",
    "User input: %s\n",
    "Answer and link: \n",
    "\"\"\"\n",
    "\n",
    "def augment( template_in, context_in, query_in ):\n",
    "    return template_in % ( context_in,  query_in )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I've done some work in quantum computing. What courses would you recommend?\"\n",
    "\n",
    "augmented_prompt = augment( prompt_template, article_txt, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting IAM Token.\n",
      "Reason: <Response [400]>\n"
     ]
    },
    {
     "ename": "WMLClientError",
     "evalue": "Error getting IAM Token.\nReason: <Response [400]>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWMLClientError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# project_id = os.environ[\"PROJECT_ID\"]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m project_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m9e074867-9d55-49d5-87d1-f0f696be8d84\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_parms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai_grp/RagBot/env/lib/python3.12/site-packages/ibm_watson_machine_learning/foundation_models/model.py:82\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, model_id, credentials, params, project_id, space_id, verify)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     76\u001b[0m              model_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     77\u001b[0m              credentials: \u001b[38;5;28mdict\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m              space_id: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     81\u001b[0m              verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m     \u001b[43mModelInference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mspace_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai_grp/RagBot/env/lib/python3.12/site-packages/ibm_watson_machine_learning/foundation_models/inference/model_inference.py:130\u001b[0m, in \u001b[0;36mModelInference.__init__\u001b[0;34m(self, model_id, deployment_id, params, credentials, project_id, space_id, verify, api_client)\u001b[0m\n\u001b[1;32m    127\u001b[0m ModelInference\u001b[38;5;241m.\u001b[39m_validate_type(params, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m credentials:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m \u001b[43mAPIClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m api_client:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m api_client\n",
      "File \u001b[0;32m~/ai_grp/RagBot/env/lib/python3.12/site-packages/ibm_watson_machine_learning/client.py:367\u001b[0m, in \u001b[0;36mAPIClient.__init__\u001b[0;34m(self, wml_credentials, project_id, verify)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCLOUD_PLATFORM_SPACES \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mICP_PLATFORM_SPACES:\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;28mprint\u001b[39m(Messages\u001b[38;5;241m.\u001b[39mget_message(message_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython_3_7_3_8_framework_are_deprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice_instance \u001b[38;5;241m=\u001b[39m \u001b[43mServiceInstanceNewPlan\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvolumes \u001b[38;5;241m=\u001b[39m Volume(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mICP_PLATFORM_SPACES:\n",
      "File \u001b[0;32m~/ai_grp/RagBot/env/lib/python3.12/site-packages/ibm_watson_machine_learning/instance_new_plan.py:41\u001b[0m, in \u001b[0;36mServiceInstanceNewPlan.__init__\u001b[0;34m(self, client)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# TODO: Check if this is used anywhere.. from initial searches, doesn't seem like\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# self._wml_credentials[u'instance_id'] = \"999\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# This is used in connections.py\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_href_definitions \u001b[38;5;241m=\u001b[39m HrefDefinitions(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client,\n\u001b[1;32m     36\u001b[0m                                          \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mCLOUD_PLATFORM_SPACES,\n\u001b[1;32m     37\u001b[0m                                          \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mPLATFORM_URL,\n\u001b[1;32m     38\u001b[0m                                          \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mCAMS_URL,\n\u001b[1;32m     39\u001b[0m                                          \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mICP_PLATFORM_SPACES)\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mwml_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mproceed:  \u001b[38;5;66;03m# there is no 'token' in wml_credentials\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_expiration_datetime() \u001b[38;5;241m-\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[0;32m~/ai_grp/RagBot/env/lib/python3.12/site-packages/ibm_watson_machine_learning/instance_new_plan.py:187\u001b[0m, in \u001b[0;36mServiceInstanceNewPlan._get_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_token\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mwml_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_token_refresh_possible():\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mICP:\n",
      "File \u001b[0;32m~/ai_grp/RagBot/env/lib/python3.12/site-packages/ibm_watson_machine_learning/instance_new_plan.py:215\u001b[0m, in \u001b[0;36mServiceInstanceNewPlan._create_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mICP_PLATFORM_SPACES:\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_is_IAM():\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_IAM_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapikey for IAM token is not provided in credentials for the client.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/ai_grp/RagBot/env/lib/python3.12/site-packages/ibm_watson_machine_learning/instance_new_plan.py:276\u001b[0m, in \u001b[0;36mServiceInstanceNewPlan._get_IAM_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expiration_datetime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError getting IAM Token.\u001b[39m\u001b[38;5;124m'\u001b[39m, response)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m token\n",
      "\u001b[0;31mWMLClientError\u001b[0m: Error getting IAM Token.\nReason: <Response [400]>"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "\n",
    "model_id = \"google/flan-t5-xxl\"\n",
    "\n",
    "gen_parms = { \n",
    "    \"DECODING_METHOD\" : \"greedy\", \n",
    "    \"MIN_NEW_TOKENS\" : 1, \n",
    "    \"MAX_NEW_TOKENS\" : 200 \n",
    "}\n",
    "\n",
    "# project_id = os.environ[\"PROJECT_ID\"]\n",
    "project_id = \"9e074867-9d55-49d5-87d1-f0f696be8d84\"\n",
    "\n",
    "\n",
    "model = Model( model_id, credentials, gen_parms, project_id )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def generate( model_in, augmented_prompt_in ):\n",
    "    \n",
    "    generated_response = model_in.generate( augmented_prompt_in )\n",
    "\n",
    "    if ( \"results\" in generated_response ) \\\n",
    "       and ( len( generated_response[\"results\"] ) > 0 ) \\\n",
    "       and ( \"generated_text\" in generated_response[\"results\"][0] ):\n",
    "        return generated_response[\"results\"][0][\"generated_text\"]\n",
    "    else:\n",
    "        print( \"The model failed to generate an answer\" )\n",
    "        print( \"\\nDebug info:\\n\" + json.dumps( generated_response, indent=3 ) )\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m generate( \u001b[43mmodel\u001b[49m, augmented_prompt )\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m( output )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "output = generate( model, augmented_prompt )\n",
    "print( output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchAndAnswer( knowledge_base_in, model ):\n",
    "    \n",
    "    question = input( \"Type your question:\\n\")\n",
    "    if not re.match( r\"\\S+\", question ):\n",
    "        print( \"No question\")\n",
    "        return\n",
    "        \n",
    "    # Retrieve the relevant content\n",
    "    top_matching_index = search( question, knowledge_base_in )\n",
    "    if top_matching_index < 0:\n",
    "        print( \"No good answer was found in the knowledge base\" )\n",
    "        return;\n",
    "    asset = knowledge_base_in[top_matching_index]\n",
    "    asset_txt = asset[\"txt\"]\n",
    "    \n",
    "    # Augment a prompt with context\n",
    "    augmented_prompt = augment( prompt_template, asset_txt, question )\n",
    "    \n",
    "    # Generate output\n",
    "    output = generate( model, augmented_prompt )\n",
    "    if not re.match( r\"\\S+\", output ):\n",
    "        print( \"The model failed to generate an answer\")\n",
    "    print( \"\\nAnswer:\\n\" + output )\n",
    "    print( \"\\nSource: \\\"\" + asset[\"title\"] + \"\\\", \" + asset[\"Author\"] + \" (\" + asset[\"Published\"] + \")\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searchAndAnswer( knowledge_base, model )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
